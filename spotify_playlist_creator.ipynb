{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ardaakcabuyuk/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import spotipy\n",
    "import spotipy.util as util\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "from spotipy import oauth2\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble.forest import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import base64\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_credentials():\n",
    "    cid = '8c4cb3ef1c0c412181ea69d07b3df0ca'\n",
    "    secret = 'a07e05c762a24e12933c4c118c6c18ca'\n",
    "    redirect_uri = 'http://localhost:8910/callback'\n",
    "    return cid, secret, redirect_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dataset_path):\n",
    "    with open(dataset_path, 'r') as token_file:\n",
    "        lines = csv.reader(token_file)\n",
    "        dataset = list(lines)\n",
    "        data = np.array(dataset)   \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNPredictor:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.preprocessing()\n",
    "        self.train()\n",
    "    \n",
    "    def preprocessing(self):\n",
    "        indices = []\n",
    "        self.id_index = -1\n",
    "        info = []\n",
    "        choose = -1\n",
    "        for i in range(self.data.shape[1]):\n",
    "            if self.data[0][i] in ['key', 'artists', 'release_date', 'name', 'id']:\n",
    "                indices.append(i)\n",
    "                if self.data[0][i] == 'id':\n",
    "                    self.id_index = i\n",
    "\n",
    "            if self.data[0][i] in ['artists', 'name']:\n",
    "                info.append(i)\n",
    "\n",
    "\n",
    "        self.data = self.data[1:,:]\n",
    "        np.random.shuffle(self.data)\n",
    "        self.ids = np.array(self.data[:,self.id_index:self.id_index+1])\n",
    "        song_info = np.array(self.data[:,info])\n",
    "        self.data = np.delete(self.data, indices, axis=1)\n",
    "        self.ids = np.ndarray.flatten(self.ids)\n",
    "        self.data = self.data.astype('float64')\n",
    "\n",
    "    def train(self):\n",
    "        self.model = NearestNeighbors(n_neighbors = 26, algorithm = 'ball_tree')\n",
    "        scalar = StandardScaler()\n",
    "        scalar.fit(self.data)\n",
    "        self.data = scalar.transform(self.data)\n",
    "        self.model.fit(self.data)\n",
    "    \n",
    "    def predict(self, song_id):\n",
    "        for j in range(self.data.shape[0]):\n",
    "            if self.ids[j] == song_id:\n",
    "                choose = j\n",
    "        distances, indices = self.model.kneighbors([self.data[choose]])\n",
    "        indices = np.ndarray.flatten(indices[:,1:])\n",
    "        tracks = self.ids[indices]\n",
    "        return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearPredictor:\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.preprocessing()\n",
    "    \n",
    "    def preprocessing(self):\n",
    "        indices = []\n",
    "        self.id_index = -1\n",
    "        info = []\n",
    "        choose = -1\n",
    "        for i in range(self.data.shape[1]):\n",
    "            if self.data[0][i] in ['key', 'artists', 'release_date', 'name', 'id']:\n",
    "                indices.append(i)\n",
    "                if self.data[0][i] == 'id':\n",
    "                    self.id_index = i\n",
    "\n",
    "            if self.data[0][i] in ['artists', 'name']:\n",
    "                info.append(i)\n",
    "\n",
    "\n",
    "        self.data = self.data[1:,:]\n",
    "        np.random.shuffle(self.data)\n",
    "        self.ids = np.array(self.data[:,self.id_index:self.id_index+1])\n",
    "        self.song_info = np.array(self.data[:,info])\n",
    "        self.data = np.delete(self.data, indices, axis=1)\n",
    "        self.ids = np.ndarray.flatten(self.ids)\n",
    "        self.data = self.data.astype('float64')\n",
    "    \n",
    "    def train_and_predict(self, song_id):\n",
    "        knnmodel = NearestNeighbors(n_neighbors = 5001, algorithm = 'ball_tree')\n",
    "        scalar = StandardScaler()\n",
    "        scalar.fit(self.data)\n",
    "        self.data = scalar.transform(self.data)\n",
    "        knnmodel.fit(self.data)\n",
    "        \n",
    "        for j in range(self.data.shape[0]):\n",
    "            if self.ids[j] == song_id:\n",
    "                self.choose = j\n",
    "        \n",
    "        distances, indices = knnmodel.kneighbors([self.data[self.choose]])\n",
    "        indices = np.ndarray.flatten(indices[:,1:])\n",
    "        tracks = self.ids[indices]\n",
    "        tracks = np.ndarray.flatten(tracks)\n",
    "        \n",
    "        relevances = []\n",
    "        threshold = 100\n",
    "        relevance = threshold\n",
    "        for i, _ in enumerate(tracks):\n",
    "            relevances.append(relevance)\n",
    "            relevance -= 0.0006\n",
    "        \n",
    "        song_train = self.data[indices]\n",
    "        self.model = LinearRegression().fit(song_train, relevances)\n",
    "        predictions = self.model.predict(self.data)\n",
    "        sort_indices = np.argsort(predictions)[::-1]\n",
    "        predictions = np.array(predictions)\n",
    "        predictions = predictions.astype('float64')\n",
    "        predictions = predictions[sort_indices]\n",
    "        \n",
    "        first_threshold_index = 0\n",
    "        for i in range(predictions.shape[0]):\n",
    "            if predictions[i] <= threshold:\n",
    "                first_threshold_index = i\n",
    "                break\n",
    "\n",
    "        playlist_added = self.ids[sort_indices][first_threshold_index:first_threshold_index+100]\n",
    "        \n",
    "        return playlist_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestPredictor:\n",
    "    \n",
    "    def __init__(self, data, sp, username, playlist_id):\n",
    "        self.data = data\n",
    "        self.sp = sp\n",
    "        self.username = username\n",
    "        self.playlist_id = playlist_id\n",
    "        self.preprocess()\n",
    "    \n",
    "    def preprocess(self):\n",
    "        self.data = self.data[1:, :]\n",
    "        song_valence = self.data[:, 17]\n",
    "        song_acousticness = self.data[:, 0]\n",
    "        song_artists = self.data[:, 1]\n",
    "        song_danceability = self.data[:, 2]\n",
    "\n",
    "        song_duration_ms = self.data[:, 3]\n",
    "        song_energy = self.data[:, 4]\n",
    "        song_id = self.data[:, 6]\n",
    "        song_popularity = self.data[:, 13]\n",
    "\n",
    "        song_instrumentalness = self.data[:, 7]\n",
    "        song_key = self.data[:, 8]\n",
    "        song_liveness = self.data[:, 9]\n",
    "        song_loudness = self.data[:, 10]\n",
    "\n",
    "        song_mode = self.data[:, 11]\n",
    "        song_name = self.data[:, 12]\n",
    "        song_speechiness = self.data[:, 15]\n",
    "        song_tempo = self.data[:, 16]\n",
    "        song_year = self.data[:, 18]\n",
    "\n",
    "        self.song_info2 = {'name': [], 'id': [], 'artists': []}\n",
    "        features_dict = {'valence': [], 'year': [], 'popularity': [], 'acousticness': [], 'danceability': [], 'duration_ms': [],\n",
    "                         'energy': [], 'instrumentalness': [], 'key': [], 'liveness': [], 'loudness': [], 'mode': [],\n",
    "                         'speechiness': [], 'tempo': []}\n",
    "        for i in range(0, self.data.shape[0]):\n",
    "            self.song_info2['name'].append(song_name[i])\n",
    "            self.song_info2['id'].append(song_id[i])\n",
    "            self.song_info2['artists'].append(song_artists[i])\n",
    "            features_dict['valence'].append(song_valence[i])\n",
    "            features_dict['acousticness'].append(song_acousticness[i])\n",
    "            features_dict['danceability'].append(song_danceability[i])\n",
    "            features_dict['duration_ms'].append(song_duration_ms[i])\n",
    "            features_dict['popularity'].append(song_popularity[i])\n",
    "            features_dict['energy'].append(song_energy[i])\n",
    "            features_dict['instrumentalness'].append(song_instrumentalness[i])\n",
    "            features_dict['key'].append(song_key[i])\n",
    "            features_dict['liveness'].append(song_liveness[i])\n",
    "            features_dict['loudness'].append(song_loudness[i])\n",
    "            features_dict['mode'].append(song_mode[i])\n",
    "            features_dict['speechiness'].append(song_speechiness[i])\n",
    "            features_dict['tempo'].append(song_tempo[i])\n",
    "            features_dict['year'].append(song_year[i])\n",
    "        # playlist_df = pd.DataFrame(features_dict, index=song_info['name'])\n",
    "\n",
    "        # Create a dataframe of your playlist including tracks' names and audio features\n",
    "        sourcePlaylist = self.sp.user_playlist(self.username, self.playlist_id)\n",
    "        tracks = sourcePlaylist[\"tracks\"]\n",
    "        self.songs = tracks[\"items\"]\n",
    "\n",
    "        track_ids = []\n",
    "        track_names = []\n",
    "\n",
    "        for i in range(0, len(self.songs)):\n",
    "            if self.songs[i]['track']['id'] != None:  # Removes the local tracks in your playlist if there is any\n",
    "                track_ids.append(self.songs[i]['track']['id'])\n",
    "                track_names.append(self.songs[i]['track']['name'])\n",
    "\n",
    "        features = []\n",
    "        for i in range(0, len(track_ids)):\n",
    "            audio_features = self.sp.audio_features(track_ids[i])\n",
    "            tr = self.sp.track(track_ids[i])['popularity']\n",
    "            year = int(self.sp.track(track_ids[i])['album']['release_date'][:4])\n",
    "            for track in audio_features:\n",
    "                # print(track)\n",
    "                features.append(track)\n",
    "            features[i]['popularity'] = tr\n",
    "            features[i]['year'] = year\n",
    "        playlist_df = pd.DataFrame(features, index=track_names)\n",
    "\n",
    "        for j in range(0, len(features)):\n",
    "            indexx = (np.linspace(0, len(features) - 1, num=len(features))).astype(int)\n",
    "            indexx = np.delete(indexx, j)\n",
    "            input_ = np.zeros(12)\n",
    "            input_[0] = (len(features) * playlist_df['valence'][j] + np.sum(playlist_df['valence'][indexx])) / (2 * len(features) - 1)\n",
    "            input_[1] = (len(features) * playlist_df['acousticness'][j] + np.sum(playlist_df['acousticness'][indexx])) / (2 * len(features) - 1)\n",
    "            input_[2] = (len(features) * playlist_df['danceability'][j] + np.sum(playlist_df['danceability'][indexx])) / (2 * len(features) - 1)\n",
    "            input_[3] = (len(features) * playlist_df['popularity'][j] + np.sum(playlist_df['popularity'][indexx])) / (2 * len(features) - 1)\n",
    "            input_[4] = (len(features) * playlist_df['energy'][j] + np.sum(playlist_df['energy'][indexx])) / (2 * len(features) - 1)\n",
    "            input_[5] = (len(features) * playlist_df['instrumentalness'][j] + np.sum(playlist_df['instrumentalness'][1:])) / (2 * len(features) - 1)\n",
    "            input_[6] = (len(features) * playlist_df['liveness'][j] + np.sum(playlist_df['liveness'][indexx])) / (2 * len(features) - 1)\n",
    "            input_[7] = (len(features) * playlist_df['loudness'][j] + np.sum(playlist_df['loudness'][indexx])) / (2 * len(features) - 1)\n",
    "            input_[8] = (len(features) * playlist_df['mode'][j] + np.sum(playlist_df['mode'][indexx])) / (2 * len(features) - 1)\n",
    "            input_[9] = (len(features) * playlist_df['speechiness'][j] + np.sum(playlist_df['speechiness'][indexx])) / (2 * len(features) - 1)\n",
    "            input_[10] = (len(features) * playlist_df['tempo'][j] + np.sum(playlist_df['tempo'][indexx])) / (2 * len(features) - 1)\n",
    "            input_[11] = (len(features) * playlist_df['year'][j] + np.sum(playlist_df['year'][indexx])) / (2 * len(features) - 1)\n",
    "\n",
    "            features_array = np.zeros((self.data.shape[0] + 1, 12))\n",
    "\n",
    "            features_array[:self.data.shape[0], 0] = np.array(features_dict['valence']).T\n",
    "            features_array[:self.data.shape[0], 1] = np.array(features_dict['acousticness']).T\n",
    "            features_array[:self.data.shape[0], 2] = np.array(features_dict['danceability']).T\n",
    "            features_array[:self.data.shape[0], 3] = np.array(features_dict['popularity']).T\n",
    "            features_array[:self.data.shape[0], 4] = np.array(features_dict['energy']).T\n",
    "            features_array[:self.data.shape[0], 5] = np.array(features_dict['instrumentalness']).T\n",
    "            features_array[:self.data.shape[0], 6] = np.array(features_dict['liveness']).T\n",
    "            features_array[:self.data.shape[0], 7] = np.array(features_dict['loudness']).T\n",
    "            features_array[:self.data.shape[0], 8] = np.array(features_dict['mode']).T\n",
    "            features_array[:self.data.shape[0], 9] = np.array(features_dict['speechiness']).T\n",
    "            features_array[:self.data.shape[0], 10] = np.array(features_dict['tempo']).T\n",
    "            features_array[:self.data.shape[0], 11] = np.array(features_dict['year']).T\n",
    "\n",
    "            features_array[self.data.shape[0], :] = input_\n",
    "\n",
    "            self.features_array = features_array.astype('float64')\n",
    "        \n",
    "    def train_and_predict(self):\n",
    "        model = NearestNeighbors(n_neighbors=5000, algorithm='ball_tree')\n",
    "\n",
    "        scalar = StandardScaler()\n",
    "        scalar.fit(self.features_array)\n",
    "        self.features_array = scalar.transform(self.features_array)\n",
    "        input_2 = self.features_array[self.data.shape[0], :]\n",
    "        model.fit(self.features_array[:self.data.shape[0], :])\n",
    "        distances, indices = model.kneighbors([input_2])\n",
    "        recorded_indices2 = indices\n",
    "\n",
    "        closest_1000_point = {'valence': [], 'year': [], 'popularity': [], 'mode': [], 'acousticness': [],\n",
    "                              'danceability': [],\n",
    "                              'energy': [], 'instrumentalness': [], 'liveness': [], 'loudness': [], 'speechiness': [],\n",
    "                              'tempo': [], 'ratings': []}\n",
    "\n",
    "        for k in range(0, 5000):\n",
    "            closest_1000_point['valence'].append(self.features_array[indices[0, k], 0])\n",
    "            closest_1000_point['acousticness'].append(self.features_array[indices[0, k], 1])\n",
    "            closest_1000_point['danceability'].append(self.features_array[indices[0, k], 2])\n",
    "            closest_1000_point['popularity'].append(self.features_array[indices[0, k], 3])\n",
    "            closest_1000_point['energy'].append(self.features_array[indices[0, k], 4])\n",
    "            closest_1000_point['instrumentalness'].append(self.features_array[indices[0, k], 5])\n",
    "            closest_1000_point['liveness'].append(self.features_array[indices[0, k], 6])\n",
    "            closest_1000_point['loudness'].append(self.features_array[indices[0, k], 7])\n",
    "            closest_1000_point['mode'].append(self.features_array[indices[0, k], 8])\n",
    "            closest_1000_point['speechiness'].append(self.features_array[indices[0, k], 9])\n",
    "            closest_1000_point['tempo'].append(self.features_array[indices[0, k], 10])\n",
    "            closest_1000_point['year'].append(self.features_array[indices[0, k], 11])\n",
    "\n",
    "            rem = k // 500\n",
    "            closest_1000_point['ratings'].append(10 - rem)\n",
    "        playlist_dfk = pd.DataFrame(closest_1000_point)\n",
    "        x_train2 = playlist_dfk.drop(['ratings'], axis=1)\n",
    "        y_train2 = playlist_dfk['ratings']\n",
    "        #playlist_creator(X_train, y_train, recorded_indices, song_info, sp, playlist_recs['id'])\n",
    "        #playlist_creator(x_train2, y_train2, recorded_indices2, song_info2, spr, playlist_id):\n",
    "        warnings.filterwarnings('ignore')\n",
    "\n",
    "        # CELL [9]\n",
    "        # Random Forests second\n",
    "        best_score = 0\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "        for train_index, test_index in skf.split(x_train2, y_train2):\n",
    "            # Decision Trees First\n",
    "            x_train_cv = np.array(x_train2)[train_index, :]\n",
    "            x_test_cv = np.array(x_train2)[test_index, :]\n",
    "            y_train_cv = np.array(y_train2)[train_index]\n",
    "            y_test_cv = np.array(y_train2)[test_index]\n",
    "\n",
    "            gcv1 = GridSearchCV(RandomForestClassifier(n_estimators=100, n_jobs=-1), n_jobs=-1, param_grid={'max_features': range(3, 6), 'min_samples_leaf': [4, 5, 6], 'max_depth': [11, 12, 13, 14, 15]})\n",
    "            gcv1.fit(x_train_cv, y_train_cv)\n",
    "            print(gcv1.best_estimator_)\n",
    "            print(gcv1.best_score_)\n",
    "            score = gcv1.best_score_\n",
    "            if score > best_score:\n",
    "                recorded_train_indexes = train_index\n",
    "                recorded_test_indexes = test_index\n",
    "                recorded_best_parameters = gcv1.best_estimator_\n",
    "        # CELL [10]\n",
    "\n",
    "        # Make predictions\n",
    "        X_train_set = np.array(x_train2)[recorded_train_indexes, :]\n",
    "        X_test_set = np.array(x_train2)[recorded_test_indexes, :]\n",
    "        y_train_set = np.array(y_train2)[recorded_train_indexes]\n",
    "        y_test_set = np.array(y_train2)[recorded_test_indexes]\n",
    "        gcv1.best_estimator_ = recorded_best_parameters\n",
    "        gcv1.best_estimator_.fit(X_train_set, y_train_set)\n",
    "        # rec_playlist_df_scaled = StandardScaler().fit_transform(rec_playlist_df)\n",
    "        # rec_playlist_df_pca = pca1.transform(rec_playlist_df_scaled)\n",
    "        # X_test_last = csr_matrix(hstack([rec_playlist_df_pca, X_test_names]))\n",
    "        y_pred_class = gcv1.best_estimator_.predict(X_test_set)\n",
    "        # print(y_pred_class)\n",
    "        # CELL [11]\n",
    "        rec_playlist_ratings = y_pred_class\n",
    "        # rec_playlist_df = rec_playlist_df.sort_values('ratings', ascending = False)\n",
    "        # rec_playlist_df = rec_playlist_df.reset_index()\n",
    "        # Pick the top ranking tracks to add your new playlist 9, 10 will work\n",
    "        ten_indexes = []\n",
    "        for k in range(0, len(y_pred_class)):\n",
    "            if y_pred_class[k] == 10:\n",
    "                ten_indexes.append(k)\n",
    "        # recs_to_add = rec_playlist_df[rec_playlist_df['ratings']>=9]['index'].values.tolist()\n",
    "\n",
    "        recomended_song_indexes = []\n",
    "        for k in ten_indexes:\n",
    "            recomended_song_indexes.append(recorded_indices2[0, recorded_test_indexes[k]])\n",
    "        # for i in nine_indexes:\n",
    "        #    recomended_song_indexes.append(recorded_indices[0, test_index[i]])\n",
    "        # print(recomended_song_indexes)\n",
    "\n",
    "        # Check what is about to happen :)\n",
    "        # for i in recomended_song_indexes:\n",
    "        #     print(song_info['id'][i])\n",
    "        # Add tracks to the new playlist\n",
    "        tracks = []\n",
    "        for k in recomended_song_indexes[:len(self.songs)*3]:\n",
    "            tracks.append(self.song_info2['id'][k])\n",
    "        return np.array(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_playlist(playlist_name, tracks, username, client_id, client_secret, redirect_uri):\n",
    "    scope = \"playlist-modify-public\"\n",
    "    token = util.prompt_for_user_token(username,scope,client_id=client_id,client_secret=client_secret,redirect_uri=redirect_uri) \n",
    "    sp = spotipy.Spotify(auth=token)\n",
    "    sp.user_playlist_create(username, name=playlist_name)\n",
    "    playlists = sp.user_playlists(username)\n",
    "    tracks = np.ndarray.flatten(tracks)\n",
    "    tracks = list(tracks)\n",
    "    sp.user_playlist_add_tracks(username, playlists['items'][0]['id'], tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_playlist_kNN():\n",
    "    cid, secret, redirect_uri = get_credentials()\n",
    "    data = read_data('./data/data.csv')\n",
    "    knnPredictor = KNNPredictor(data)\n",
    "    song_id = input('Enter song ID: ')\n",
    "    tracks = knnPredictor.predict(song_id)\n",
    "    username = input('Enter username: ')\n",
    "    playlist_name = input('Enter playlist name: ')\n",
    "    create_playlist(playlist_name, tracks, username, client_id=cid, client_secret=secret, redirect_uri=redirect_uri)\n",
    "\n",
    "def create_playlist_LinearRegression():\n",
    "    cid, secret, redirect_uri = get_credentials()\n",
    "    data = read_data('./data/data.csv')\n",
    "    linearPredictor = LinearPredictor(data)\n",
    "    song_id = input('Enter song ID: ')\n",
    "    tracks = linearPredictor.train_and_predict(song_id)\n",
    "    username = input('Enter username: ')\n",
    "    playlist_name = input('Enter playlist name: ')\n",
    "    create_playlist(playlist_name, tracks, username, client_id=cid, client_secret=secret, redirect_uri=redirect_uri)\n",
    "\n",
    "def create_playlist_RandomForestRegression():\n",
    "    cid, secret, redirect_uri = get_credentials()\n",
    "    data = read_data('./data/data.csv')\n",
    "    \n",
    "    scope = \"user-library-read playlist-modify-public playlist-read-private user-library-modify\"\n",
    "    username = input('Enter username: ')\n",
    "    playlist_id = input('Enter Playlist ID: ')\n",
    "    token = util.prompt_for_user_token(username,scope,client_id=cid,client_secret=secret,redirect_uri=redirect_uri) \n",
    "    sp = spotipy.Spotify(auth=token)\n",
    "    forestPredictor = RandomForestPredictor(data, sp, username, playlist_id)\n",
    "    tracks = forestPredictor.train_and_predict()\n",
    "    playlist_name = input('Enter playlist name: ')\n",
    "    create_playlist(playlist_name, tracks, username, client_id=cid, client_secret=secret, redirect_uri=redirect_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter song ID: 1C2QJNTmsTxCDBuIgai8QV\n",
      "Enter username: ardabyk07\n",
      "Enter playlist name: Playlist Generated for Ercüment Çiçek (with Linear Regression)\n"
     ]
    }
   ],
   "source": [
    "create_playlist_LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
